# -*- coding: utf-8 -*-
"""Boston.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iSKw4FpqlQUjecl6y5sXW-5u6XkHcIZ8

#Model evaluation for boston house data
"""

#importing libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.mlab as mlab

"""APPEND FIVE ROWS IN BOSTON DATA SET AND FINALIZING THE DATASET
---


"""

### To get the BOSTON data from sklearn datasets
from sklearn import datasets
boston= datasets.load_boston ()
####Now transform the data as a pandasâ€™s DATAFRAME
import pandas as pd
df = pd.DataFrame(boston.data ,columns = boston.feature_names)
df['price']=boston.target

# inputting five row values
datarowsSeries = [pd.Series([0.069, 10, 2.3, 0, 0.53, 6.5, 65.2, 4.01, 1, 290, 15, 395, 4.9, 24.0], index=df.columns ),
                  pd.Series([0.69, 10, 2.3, 0, 0.5, 6.5, 65.2, 4.1, 1, 290, 15, 395, 4.9, 24.3],index=df.columns ),
                  pd.Series([0.68, 11, 2.4, 0, 0.6, 6.6, 65.1, 4.0, 1, 291, 13, 390, 4.2, 24.2],index=df.columns ),
                  pd.Series([0.67, 12, 2.5, 0, 0.4, 6.5, 65.3, 4.2, 1, 292, 14, 392, 4.3, 24.1],index=df.columns ),
                  pd.Series([0.66, 13, 2.4, 0, 0.7, 6.5, 65.4, 4.1, 1, 293, 16, 391, 4.4, 24.2],index=df.columns ),
                  ]

#row array conversion to dataframe
datarowsSeries = pd.DataFrame(datarowsSeries)

#row array conversion to dataframe
datarowsSeries = pd.DataFrame(datarowsSeries)

#udating colums by adding id digits
datarowsSeries.CRIM.iloc[1: ] = datarowsSeries.CRIM.iloc[1: ] + 54
datarowsSeries.ZN.iloc[1: ] = datarowsSeries.ZN.iloc[1: ] + 54
datarowsSeries.TAX.iloc[1: ] = datarowsSeries.TAX.iloc[1: ] + 54
datarowsSeries.PTRATIO.iloc[1: ] = datarowsSeries.PTRATIO.iloc[1: ] + 54
datarowsSeries.B.iloc[1: ] = datarowsSeries.B.iloc[1: ] + 54
datarowsSeries.price.iloc[1: ] = datarowsSeries.price.iloc[1: ] + 54
datarowsSeries.INDUS.iloc[1: ] = datarowsSeries.INDUS.iloc[1: ] + .54
datarowsSeries.NOX.iloc[1: ] = datarowsSeries.NOX.iloc[1: ] + .54
datarowsSeries.RM.iloc[1: ] = datarowsSeries.RM.iloc[1: ] + .54
datarowsSeries.AGE.iloc[1: ] = datarowsSeries.AGE.iloc[1: ] + .54
datarowsSeries.DIS.iloc[1: ] = datarowsSeries.DIS.iloc[1: ] + .54
datarowsSeries.LSTAT.iloc[1: ] = datarowsSeries.LSTAT.iloc[1: ] + .54

#data frame merging
frames = [df, datarowsSeries]
df = pd.concat(frames, join='inner', ignore_index=True)

df

"""INDEX DESCRIPTION
---


CRIM - per capita crime rate by *town*

ZN - proportion of residential land zoned for lots over 25,000 sq.ft.

INDUS - proportion of non-retail business acres per town.

CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)

NOX - nitric oxides concentration (parts per 10 million)

RM - average number of rooms per dwelling

AGE - proportion of owner-occupied units built prior to 1940

DIS - weighted distances to five Boston employment centres

RAD - index of accessibility to radial highways

TAX - full-value property-tax rate per $10,000

PTRATIO - pupil-teacher ratio by town

B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town

LSTAT - % lower status of the population

MEDV - Median value of owner-occupied homes in $1000's


"""

df.isnull().values.any()

df.dtypes

df.shape

df.info()

"""**1. Illustrate the following summary information in Python:**
---

(i)Read the data and construct some appropriate graphs for each of the variables with interpretation.


(ii) Calculate some measures (if appropriate), for instance, mean, median, mode,
minimum, maximum, quartiles, Standard deviation, etc., for each of the variables
according to their level of measurements. Also, calculate covariance matrix and
correlation-matrix of the variables.


(iii) Construct the pair plots of those variables with different colors for different house prices (high > 20, low <=20) in Boston Housing data.

---

***2. To classify the different house prices (high > 20, low <=20) in Boston Housing data use the following supervised learning methods: ***
---

(i) Run the Logistic Regression model to classify the different categories. Find the confusion matrix and ROC curve. Hence, calculate and interpret: Predictive value positive and negative, Accuracy, Sensitivity, and Specificity of the test.

(ii) Run the Decision Trees to classify the different categories. Find the confusion matrix and ROC curve. Hence, calculate and interpret: Predictive value positive and negative, Accuracy, Sensitivity, and Specificity of the test.

(iii) Run the Random Forest to classify the different categories. Find the confusion matrix and ROC curve. Hence, calculate and interpret: Predictive value positive and negative, Accuracy, Sensitivity, and Specificity of the test.

(iv) Run the Support Vector Machines to classify the different categories. Find the confusion matrix and ROC curve. Hence, calculate and interpret: Predictive value positive and negative, Accuracy, Sensitivity, and Specificity of the test.

(v) Hence, evaluate the best performed model for your study.

---
"""

from google.colab import drive
drive.mount('/content/drive')

"""**Solution (1)=>(i)**
---
**Appropriate graphs for each of the variables with interpretation**.


"""

fig, axs = plt.subplots(ncols=7, nrows=2, figsize=(20, 10))
index = 0
axs = axs.flatten()
for k,v in df.items():
    sns.histplot(v, ax=axs[index])
    index += 1
plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)

"""Interpretation:
---


The histogram shows the frequency of data points, location, skewness, and presence of outliers in the dataset.

By plotting a histogram for this dataset The histogram also shows that columns CRIM and ZN have negatively skewed and B has positively skewed distributions. Also, Price and RM look to have a normal distribution (the predictions), and other columns seem to have a normal or bimodal distribution of data except CHAS (which is a discrete variable).

"""

##################################### BOXPLOT BEFORE FOR DETECTING OUTLIER ############################################
from scipy import stats

fig, axs = plt.subplots(ncols=7, nrows=2, figsize=(20, 10))
index = 0
axs = axs.flatten()
for k,v in df.items():
    sns.boxplot(y=k, data=df, ax=axs[index])
    index += 1
plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)

"""INTERPRETATION:
---


Box plot graphically shows the spread of a numerical variable through quartiles and gives information about variability and dispersion of the data using a five-number summary. These include minimum, first quartile(Q1-25th percentile), median, third quartile (Q3-75th percentile), and maximum.

It is used for outlier detection (data points below the lower fence and above the maximum fence are referred to as outliers.

From the plotted graph it is visible that CRIM, ZN, RM, and B have larger outliers. 

"""

##################### NUMBER OF OUTLIER IN EACH COLUMN #########################################

for x in ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']:
    q75,q25 = np.percentile(df.loc[:,x],[75,25])
    intr_qr = q75-q25
 
    max = q75+(1.5*intr_qr)
    min = q25-(1.5*intr_qr)
 
    df.loc[df[x] < min,x] = np.nan
    df.loc[df[x] > max,x] = np.nan
df.isnull().sum()

#################################### OUTLIER REPLACEMENT WITH THE MEAN OF THE OUTLIER DETECTED COLUMN ################################

df['CRIM'].fillna(int(df['CRIM'].mean()), inplace=True)
df['ZN'].fillna(int(df['ZN'].mean()), inplace=True)
df['CHAS'].fillna(int(df['CHAS'].mean()), inplace=True)
df['NOX'].fillna(int(df['NOX'].mean()), inplace=True)
df['RM'].fillna(int(df['RM'].mean()), inplace=True)
df['DIS'].fillna(int(df['DIS'].mean()), inplace=True)
df['PTRATIO'].fillna(int(df['PTRATIO'].mean()), inplace=True)
df['B'].fillna(int(df['B'].mean()), inplace=True)
df['LSTAT'].fillna(int(df['LSTAT'].mean()), inplace=True)
df.isnull().sum()

############################################ BOXPLOT AFTER REPLACING THE OUTLIER THROUGH MEAN #######################

from scipy import stats

fig, axs = plt.subplots(ncols=7, nrows=2, figsize=(20, 10))
index = 0
axs = axs.flatten()
for k,v in df.items():
    sns.boxplot(y=k, data=df, ax=axs[index])
    index += 1
plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)

################################################ CORRELATION HEATMAP ###########################################

plt.figure(figsize=(15, 12))
sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True, cmap='vlag') # cmap='BrBG'
plt.title('Correlation Map', fontdict={'fontsize':12}, pad=12);

"""INTERPRETATION:
---


From the correlation matrix, we see RM(positively) and LSTAT(Negatively) are highly correlated features. The columns LSTAT, INDUS, RAD, TAX, NOX, and AGE have a negative correlation with the price of the house, and others have a very poor positive correlation for determining the price of the house.

**Solution (1) => (ii)**
---
**Some measures, for instance, mean, median, mode,
minimum, maximum, quartiles, Standard deviation,covariance matrix and
correlation-matrix of the variables.**
"""

df.describe()

df.corr()

df.cov()

"""**Solution (1) => (iii)**
---
**Pair plots of those variables with different colors for different house prices (high > 20, low <=20) in Boston Housing data**
"""

df["price"] = np.where(df["price"] <= 20, 1, 2)
df['price']=df['price'].map({1:'Low', 2:'High'})

sns.set_style('darkgrid');
sns.pairplot(df, hue = 'price', height = 5)
plt.show()

df['price']=df['price'].map({'Low':0, 'High':1})

df = df.drop(['CHAS'],axis = 1)

"""**Solution (2)**
---
**Different house prices (high > 20, low <=20) in Boston Housing data  using the some supervised learning methods(Logistic Regression, decision Tree, Random Forest, Support Vector Machine):**
"""

X = df.drop(['price'], axis = 1)
Y = df['price']

# Split dataset into training set and test set which is globally done for each model
 
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=999) # 80% training and 20% test

"""**Solution (2) => (i)**
---
**Logistic Regression to classify the different categories.confusion matrix,calculation and interpretation of Predictive value positive and negative, Accuracy, Sensitivity, and Specificity of the test.**
"""

#########################logostic####################
from sklearn.linear_model import LogisticRegression
import statsmodels.api as sm


logit_model = sm.Logit(y_train, X_train)
result= logit_model.fit()
print(result.summary2())


#predicting test dataset

logmodel = LogisticRegression()
logmodel.fit(X_train, y_train)
Y_pred = logmodel.predict(X_test)
print('logistic regression model accurecy for boston house data:{:.2f}'.format(logmodel.score(X_test, y_test)))



#classification report
from sklearn.metrics import classification_report
 
print(classification_report(y_test, Y_pred))

#confusion matrics
import matplotlib.pyplot as plt
from sklearn.metrics import plot_confusion_matrix
 
color = 'white'
matrix = plot_confusion_matrix(logmodel, X_test, y_test, cmap=plt.cm.Blues)
matrix.ax_.set_title('Confusion Matrix for logistic regression', color=color)
plt.xlabel('Predicted Label', color=color)
plt.ylabel('True Label', color=color)
plt.gcf().axes[0].tick_params(colors=color)
plt.gcf().axes[1].tick_params(colors=color)
plt.show()


# # predicted value positive, predicted value negative, accuracy, sensitivity, specificity,
cm_dt = confusion_matrix(y_test, Y_pred)
TP = cm_dt[0,0]
FP = cm_dt[0,1]
FN = cm_dt[1,0]
TN = cm_dt[1,1]

ppv = (TP/(TP+FP))
npv = (TN/(TN+FN))
accuracy = (TP+TN)/(TP+TN+FP+FN)
sensitivity = TP/(TP+FN)
specificity = TN/(TN+FP)

print("Predicted value Positive: {:.2f}".format(ppv))
print("Predicted value Negative: {:.2f}".format(npv))
print("Accuracy: {:.2f}".format(accuracy))
print("Sensitivity(Recall): {:.2f}".format(sensitivity))
print("Specificity: {:.2f}".format(specificity))

"""logistic regression model accurecy for boston house data is 85%

**Solution (2) => (II)**
---
**Decision Trees to classify the different categories.confusion matrix,calculation and interpretation of Predictive value positive and negative, Accuracy, Sensitivity, and Specificity of the test.**
"""

################# DT #################################################
from sklearn import tree
DTclf=tree.DecisionTreeClassifier()
 
DTclf.fit(X_train, y_train)
y_pred= DTclf.predict(X_test) ##y_test
 
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
print('############# DT ###############')
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(accuracy_score(y_test, y_pred))

#confusion matrics
import matplotlib.pyplot as plt
from sklearn.metrics import plot_confusion_matrix
 
color = 'white'
matrix = plot_confusion_matrix(DTclf, X_test, y_test, cmap=plt.cm.Blues)
matrix.ax_.set_title('Confusion Matrix for decision tree', color=color)
plt.xlabel('Predicted Label', color=color)
plt.ylabel('True Label', color=color)
plt.gcf().axes[0].tick_params(colors=color)
plt.gcf().axes[1].tick_params(colors=color)
plt.show()



# # predicted value positive, predicted value negative, accuracy, sensitivity, specificity,
cm_dt = confusion_matrix(y_test, y_pred)
TP = cm_dt[0,0]
FP = cm_dt[0,1]
FN = cm_dt[1,0]
TN = cm_dt[1,1]

ppv = (TP/(TP+FP))
npv = (TN/(TN+FN))
accuracy = (TP+TN)/(TP+TN+FP+FN)
sensitivity = TP/(TP+FN)
specificity = TN/(TN+FP)

print("Predicted value Positive: {:.2f}".format(ppv))
print("Predicted value Negative: {:.2f}".format(npv))
print("Accuracy: {:.2f}".format(accuracy))
print("Sensitivity(Recall): {:.2f}".format(sensitivity))
print("Specificity: {:.2f}".format(specificity))

"""**Solution (2) => (iii)**
---

**Random Forest to classify the different categories.confusion matrix,calculation and interpretation of Predictive value positive and negative, Accuracy, Sensitivity, and Specificity of the test.****
"""

################### RF ############################################
from sklearn.ensemble import RandomForestClassifier
RFclf=RandomForestClassifier(n_estimators=101)
 
RFclf.fit(X_train, y_train)
y_pred=RFclf.predict(X_test)
 
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
print('############# RF ###############')
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(accuracy_score(y_test, y_pred))

#confusion matrics
import matplotlib.pyplot as plt
from sklearn.metrics import plot_confusion_matrix
 
color = 'white'
matrix = plot_confusion_matrix(RFclf, X_test, y_test, cmap=plt.cm.Blues)
matrix.ax_.set_title('Confusion Matrix for random forest classifier', color=color)
plt.xlabel('Predicted Label', color=color)
plt.ylabel('True Label', color=color)
plt.gcf().axes[0].tick_params(colors=color)
plt.gcf().axes[1].tick_params(colors=color)
plt.show()

# # predicted value positive, predicted value negative, accuracy, sensitivity, specificity,
cm_dt = confusion_matrix(y_test, y_pred)
TP = cm_dt[0,0]
FP = cm_dt[0,1]
FN = cm_dt[1,0]
TN = cm_dt[1,1]

ppv = (TP/(TP+FP))
npv = (TN/(TN+FN))
accuracy = (TP+TN)/(TP+TN+FP+FN)
sensitivity = TP/(TP+FN)
specificity = TN/(TN+FP)

print("Predicted value Positive: {:.2f}".format(ppv))
print("Predicted value Negative: {:.2f}".format(npv))
print("Accuracy: {:.2f}".format(accuracy))
print("Sensitivity(Recall): {:.2f}".format(sensitivity))
print("Specificity: {:.2f}".format(specificity))

"""**Solution (2) => (IV)**
---
**Support Vector Machines to classify the different categories.confusion matrix,calculation and interpretation of Predictive value positive and negative, Accuracy, Sensitivity, and Specificity of the test.**
"""

######################### SVM ######################################
from sklearn.svm import SVC
SVclf = SVC(kernel='poly', degree=3)
#### can use other kernel depending your data features, e.g., (kernel='poly', degree=4), kernel='linear', Gaussian kernel: kernel = 'rbf', kernel='sigmoid'
 
SVclf.fit(X_train, y_train)
y_pred=SVclf.predict(X_test)
 
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
print('############# SVM ###############')
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(accuracy_score(y_test, y_pred))



#confusion matrics
import matplotlib.pyplot as plt
from sklearn.metrics import plot_confusion_matrix
 
color = 'white'
matrix = plot_confusion_matrix(SVclf, X_test, y_test, cmap=plt.cm.Blues)
matrix.ax_.set_title('Confusion Matrix for random forest classifier', color=color)
plt.xlabel('Predicted Label', color=color)
plt.ylabel('True Label', color=color)
plt.gcf().axes[0].tick_params(colors=color)
plt.gcf().axes[1].tick_params(colors=color)
plt.show()

# # predicted value positive, predicted value negative, accuracy, sensitivity, specificity,
cm_dt = confusion_matrix(y_test, y_pred)
TP = cm_dt[0,0]
FP = cm_dt[0,1]
FN = cm_dt[1,0]
TN = cm_dt[1,1]

ppv = (TP/(TP+FP))
npv = (TN/(TN+FN))
accuracy = (TP+TN)/(TP+TN+FP+FN)
sensitivity = TP/(TP+FN)
specificity = TN/(TN+FP)

print("Predicted value Positive: {:.2f}".format(ppv))
print("Predicted value Negative: {:.2f}".format(npv))
print("Accuracy: {:.2f}".format(accuracy))
print("Sensitivity(Recall): {:.2f}".format(sensitivity))
print("Specificity: {:.2f}".format(specificity))

"""**Solution (2) => (v)**
---
**Evaluation the best performed model of the study**
"""

### ROC

############### DT #################################################
from sklearn import tree
DTclf=tree.DecisionTreeClassifier()
DTclf.fit(X_train, y_train)
#####Predict probabilities for the test data.
probsDT = DTclf.predict_proba(X_test)
####Keep Probabilities of the positive class only.
probsDT = probsDT[:, 1]
################# RF ############################################
from sklearn.ensemble import RandomForestClassifier
RFclf=RandomForestClassifier(n_estimators=1000)
RFclf.fit(X_train, y_train)
y_pred=RFclf.predict(X_test)
#####Predict probabilities for the test data.
probsRF = RFclf.predict_proba(X_test)
####Keep Probabilities of the positive class only.
probsRF = probsRF[:, 1]
####################### SVM ######################################
from sklearn.svm import SVC
SVclf2 = SVC(kernel='rbf', C=10, gamma='auto')
#(kernel='poly', degree=4), kernel='linear', Gaussian kernel: kernel = 'rbf', kernel='sigmoid'
SVclf2.fit(X_train, y_train)
y_pred=SVclf2.predict(X_test)
probsSV = SVclf2.fit(X_train, y_train).decision_function(X_test)
############################# Logistic Regression ###########################
from sklearn.linear_model import LogisticRegression
logmodel = LogisticRegression()
logmodel.fit(X_train, y_train)
y_pred=logmodel.predict(X_test)
## calculate the fpr and tpr for all thresholds of the classification
probs = logmodel.predict_proba(X_test)
preds = probs[:,1]
from sklearn.metrics import roc_curve, roc_auc_score
###Compute the AUC Score.
auc = roc_auc_score(y_test, probsDT)
auc2 = roc_auc_score(y_test, probsRF)
auc3 = roc_auc_score(y_test, probsSV)
auc4 = roc_auc_score(y_test, preds)
print('DT AUC:', auc)
print('RF AUC2:', auc2)
print('SVM AUC3:', auc3)
print('LR AUC4:', auc4)
###Get the ROC Curve
fpr, tpr, thresholds = roc_curve(y_test, probsDT)
fpr2, tpr2, thresholds2 = roc_curve(y_test, probsRF)
fpr3, tpr3, thresholds3 = roc_curve(y_test, probsSV)
fpr4, tpr4, thresholds5 = roc_curve(y_test, preds)
####Plot ROC Curve 
plt.figure()
lw = 2
plt.plot(fpr, tpr, color='red',lw=lw, label='DT(AUC = %0.4f)' % auc)
plt.plot(fpr2, tpr2, color='green',lw=lw, label='RF(AUC = %0.4f)' % auc2)
plt.plot(fpr3, tpr3, color='purple',lw=lw, label='SVM(AUC = %0.4f)' % auc3)
plt.plot(fpr4, tpr4, color='orange',lw=lw, label='LR(AUC = %0.4f)' % auc4)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right")
plt.show()

"""Model Evaluation:
---


ROC: A receiver operator characteristic(ROC) curve is a graphical plot constructed by true positive rate(TPR) against the false positive rate(FPR). To compare classifiers common approach is to calculate area under the ROC curve which is abbreviated as AUC.

***The ROC curve for Boston housing data set results exposed AUC for random forest (0.92) is better than DT, SVM and LR. So RF(random forest) is the best classifier comparing the AUC.***

"""